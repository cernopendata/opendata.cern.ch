<collection>
<record>
<controlfield tag="001">328</controlfield>
  <datafield tag="024" ind1="7" ind2=" ">
    <subfield code="a">10.7483/OPENDATA.ATLAS.ZBP2.M5T8</subfield>
    <subfield code="2">DOI</subfield>
  </datafield>
  <datafield tag="100" ind1=" " ind2=" ">
    <subfield code="a">Rousseau, David</subfield>
  </datafield>
  <datafield tag="245" ind1=" " ind2=" ">
    <subfield code="a">Dataset from the ATLAS Higgs Boson Machine Learning Challenge 2014</subfield>
  </datafield>
  <datafield tag="260" ind1=" " ind2=" ">
    <subfield code="b">CERN Open Data Portal</subfield>
  <subfield code="c">2014</subfield>
  </datafield>
  <datafield tag="256" ind1=" " ind2=" ">
    <subfield code="a">Dataset</subfield>
    <subfield code="e">818238</subfield>
    <subfield code="t">events</subfield>
  </datafield>
  <datafield tag="256" ind1=" " ind2=" ">
    <subfield code="f">1</subfield>
    <subfield code="t">file</subfield>
  </datafield>
  <datafield tag="256" ind1=" " ind2=" ">
    <subfield code="b">60000000</subfield>
    <subfield code="t">bytes in total</subfield>
  </datafield>
  <datafield tag="520" ind1=" " ind2=" ">
    <subfield code="a">For the Challenge, we provide simulated events using the official ATLAS full detector simulator. The simulator has two parts. In the first, random proton-proton collisions are simulated based on the knowledge that we have accumulated on particle physics. It reproduces the random microscopic explosions resulting from the proton-proton collisions. In the second part, the resulting particles are tracked through a virtual model of the detector. The process yields simulated events with properties that mimic the statistical properties of the real events with additional information on what has happened during the collision, before particles are measured in the detector. The signal sample contains events in which Higgs bosons (with fixed mass 125 GeV) were produced. The background sample was generated by other known processes which can produce events with at least one electron or muon and a hadronic tau, mimicking the signal. For the sake of simplicity, only three background processes were retained for the Challenge. The first comes from the decay of the Z boson (with mass 91.2 GeV) in two taus. This decay produces events with a topology very similar to that produced by the decay of a Higgs. The second set contains events with a pair of top quarks, which can have lepton and hadronic tau among their decay. The third set involves the decay of the W boson, where one electron or muon and a hadronic tau can appear simultaneously only through imperfections of the particle identification procedure. Due to the complexity of the simulation process, each simulated event has a weight which is proportional to the conditional density divided by the instrumental density used by the simulator (an importance-sampling flavor), and normalized for integrated luminosity such that, in any region, the sum of the weights of events falling in the region is an unbiased estimate of the expected number of events falling in the same region during a given fixed time interval. In our case, the weights correspond to the quantity of real data taken during the year 2012. The weights are an artifact of the way the simulation works and so they are not part of the input to the classifier. For the Challenge, weights have been provided in the training set so the AMS can be properly evaluated. Weights were not provided it in the qualifying set since the weight distribution of the signal and background sets are very different and so they would give away the label immediately. However, in the opendata.cern.ch dataset, weights and labels have been provided for the complete dataset.</subfield>
  </datafield>
  <datafield tag="567" ind1=" " ind2=" ">
    <subfield code="a">The dataset is described using the following variables: EventId. DER_mass_MMC, DER_mass_transverse_met_lep, DER_mass_vis, DER_pt_h, DER_deltaeta_jet_jet, DER_mass_jet_jet, DER_prodeta_jet_jet, DER_deltar_tau_lep, DER_pt_tot, DER_sum_pt, DER_pt_ratio_lep_tau, DER_met_phi_centrality, DER_lep_eta_centrality, PRI_tau_pt, PRI_tau_eta, PRI_tau_phi, PRI_lep_pt, PRI_lep_eta, PRI_lep_phi, PRI_met, PRI_met_phi, PRI_met_sumet, PRI_jet_num, PRI_jet_leading_pt, PRI_jet_leading_eta, PRI_jet_leading_phi, PRI_jet_subleading_pt, PRI_jet_subleading_eta, PRI_jet_subleading_phi, PRI_jet_all_pt, Weight, Label, KaggleSet, KaggleWeight. A detailed description of the variables can be found in the documentation.</subfield>
    <subfield code="w">329</subfield>
  </datafield>
  <datafield tag="581" ind1=" " ind2=" ">
    <subfield code="a">This dataset is provided an extended version of the data provided for the Higgs Boson Machine Learning Challenge on Kaggle. For more information</subfield>
    <subfield code="w">329</subfield>
    <subfield code="y">Go to the Higgs Machine Learning documentation</subfield>
  </datafield>
  <datafield tag="583" ind1=" " ind2=" ">
    <subfield code="a"><![CDATA[ <p>The evaluation metric is the <em>approximate median significance</em> (AMS):</p>
    <p>\[ \text{AMS} = \sqrt{2\left((s+b+b_r) \log \left(1 + \frac{s}{b + b_r}\right)-s\right)}\]</p>
    <p>where</p>
    <ul>
    <li>\\(s, b\\): unnormalized true positive and false positive rates, respectively,</li>
    <li>\\(b_r =10\\) is the constant regularization term,</li>
    <li>\\(\log\\) is the natural log.</li>
    </ul>
    <p>More precisely, let \\((y_1, \ldots, y_n) \in \{\text{b},\text{s}\}^n\\) be the vector of true test labels, let \\((\hat{y}_1, \ldots, \hat{y}_n) \in \{\text{b},\text{s}\}^n\\) be the vector of predicted (submitted) test labels, and let \\((w_1, \ldots, w_n) \in {\mathbb{R}^+}^n\\) be the vector of weights. Then</p>
    <p>\[ s = \sum_{i=1}^n w_i\mathbb{1}\{y_i = \text{s}\} \mathbb{1}\{\hat{y}_i = \text{s}\} \]</p>
    <p>and</p>
    <p>\[ b = \sum_{i=1}^n w_i\mathbb{1}\{y_i = \text{b}\} \mathbb{1}\{\hat{y}_i = \text{s}\}, \]</p>
    <p>where the indicator function \\(\mathbb{1}\{A\}\\) is 1 if its argument \\(A\\) is true and 0 otherwise.</p>
    <p>For more information on the statistical model and the derivation of the metric, see the documentation.</p> ]]></subfield>
    <subfield code="w">329</subfield>
  </datafield>
  <datafield tag="693" ind1=" " ind2=" ">
    <subfield code="a">CERN-LHC</subfield>
    <subfield code="e">ATLAS</subfield>
  </datafield>
  <datafield tag="856" ind1="4" ind2=" ">
    <subfield code="a">https://www.kaggle.com/c/higgs-boson</subfield>
    <subfield code="y">Go to the Higgs Boson Machine Learning Challenge on Kaggle</subfield>
  </datafield>
  <datafield tag="980" ind1=" " ind2=" ">
    <subfield code="a">ATLAS-Higgs-Challenge-2014</subfield>
  </datafield>
</record>
<record>
<controlfield tag="001">329</controlfield>
  <datafield tag="024" ind1="7" ind2=" ">
    <subfield code="a">10.7483/OPENDATA.ATLAS.MQ5J.GHXA</subfield>
    <subfield code="2">DOI</subfield>
  </datafield>
  <datafield tag="100" ind1=" " ind2=" ">
    <subfield code="a">Adam-Bourdarios, Claire</subfield>
  </datafield>
  <datafield tag="245" ind1=" " ind2=" ">
    <subfield code="a">Learning to discover: the Higgs boson machine learning challenge</subfield>
  </datafield>
  <datafield tag="260" ind1=" " ind2=" ">
    <subfield code="b">CERN Open Data Portal</subfield>
    <subfield code="c">2014</subfield>
  </datafield>
  <datafield tag="520" ind1=" " ind2=" ">
    <subfield code="a">The Higgs boson machine learning challenge (HiggsML or Challenge in short) has been set up to promote collaboration between high energy physicists and data scientists. The ATLAS experiment at CERN provided simulated data used by physicists to optimize the analysis of the Higgs boson. The Challenge is organized by a small group of ATLAS physicists and data scientists. It is hosted by Kaggle at https://www.kaggle.com/c/higgs-boson. This document provides technical background for the Challenge; reading and understanding it is not necessary to participate in the Challenge, but it is probably useful. No prior knowledge of high energy physics is required. All information on how to participate in the Challenge is available on the Kaggle web site.</subfield>
  </datafield>
  <datafield tag="516" ind1=" " ind2=" ">
    <subfield code="a">The data described in this documentation is available at</subfield>
    <subfield code="w">328</subfield>
    <subfield code="y">Go to the Higgs Machine Learning data</subfield>
  </datafield>
  <datafield tag="693" ind1=" " ind2=" ">
    <subfield code="a">CERN-LHC</subfield>
    <subfield code="e">ATLAS</subfield>
  </datafield>
  <datafield tag="700" ind1=" " ind2=" ">
    <subfield code="a">Cowan, Glen</subfield>
  </datafield>
  <datafield tag="700" ind1=" " ind2=" ">
    <subfield code="a">Germain, Cecile</subfield>
  </datafield>
  <datafield tag="700" ind1=" " ind2=" ">
    <subfield code="a">Guyon, Isabelle</subfield>
  </datafield>
  <datafield tag="700" ind1=" " ind2=" ">
    <subfield code="a">Kegl, Balazs</subfield>
  </datafield>
  <datafield tag="700" ind1=" " ind2=" ">
    <subfield code="a">Rousseau, David</subfield>
  </datafield>
  <datafield tag="856" ind1="4" ind2=" ">
    <subfield code="a">https://www.kaggle.com/c/higgs-boson</subfield>
    <subfield code="y">Go to the Higgs Boson Machine Learning Challenge on Kaggle</subfield>
  </datafield>
  <datafield tag="980" ind1=" " ind2=" ">
    <subfield code="a">ATLAS-Higgs-Challenge-2014</subfield>
  </datafield>
  <datafield tag="FFT" ind1=" " ind2=" ">
    <subfield code="a">FIX ME WITH LATEST DOCUMENT VERSION</subfield>
  </datafield>
</record>
</collection>
